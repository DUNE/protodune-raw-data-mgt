
\subsection{The protoDUNE program and detectors}
The protoDUNE program is designed for measurements with a test beam provided by a dedicated target and beamline system at the CERN SPS accelerator complex, and will help validate various DUNE technology aspects before proceeding with the construction of the principal DUNE detectors at SURF. It also has the potential to be an important platform for realistic LArTPC detector characterization (e.g. PID, shower response etc) utilizing controlled conditions of a test-beam experimental setup. The name ``protoDUNE'' currently applies to two full-scale LArTPC prototypes based on two different technologies. The ``full-scale'' designation is used to describe the fact that the prototypes contain important (and large) structural and readout elements built according to the specifications (including the size) of the eventual full detector.

The  ``single-phase'' (SP) LArTPC functions without amplification in the medium (liquid Argon) and is in essence a very large ionization chamber equipped with a large number of readout electrodes (wires), each with its own electronics chain. In this design, the front-end electronics is situated within the cryostat in order to minimize the noise (the so-called ``cold electronics design''). In the ``dual-phase'' (DP) TPC ionization electrons are extracted from liquid into gaseous phase of Argon, and drift in Argon gas towards a specially designed 2D structure on top of the detector where they multiply according to principles of proportional chamber operation. The two designs are complementary in the sense they explore different approaches to optimization of the Liquid Argon detector characteristics.

In December of 2015 the dual-phase prototype was given the official designation as a CERN experiment ``NP02'', and the single-phase was designated as ``NP04''. Both are to be deployed at CERN in 2017 and scheduled to take data in 2018. The prototypes will be placed in a specially constructed large-scale extension of the existing experimental hall located in the CERN North Area. Each prototype will be provided a dedicated optical fiber network connection to the CERN central storage facilities located in the West Area campus of CERN. The nominal bandwidth of these dedicated network connections will be 20 Gbps for each experiment. The motivations for this specific choice of nominal bandwidth will be presented in the following sections.

\subsection{Outlook for protoDUNE data characteristics}

In order to provide necessary precision for reconstruction of the ionization patterns in the LArTPC, both single-phase and dual-phase designs share the same fundamental characteristics:
\begin{itemize}
\item High spatial granularity of readout (e.g. the electrode pattern), and the resulting high channel count
\item High digitization frequency (which is essential to ensure precise position measurement along the drift direction)
\end{itemize}

\noindent
Another common factor in both designs is the relatively slow drift velocity of electrons in Liquid Argon, which is of the order of millimeters per microsecond, depending on the drift volume voltage and other parameters. This leads to substantial readout window (of the order of milliseconds) required to collect all of the ionization in the Liquid Argon volume due the event of interest. Even though the readout times are substantially different in the two designs, the net effect is similar in that due the the high digitization frequency in every channel (as explained above) this leads to a considerable amount of data per event.  Each event is comparable in size to a high-resolution digital photograph.

As will be shown in the following sections, it is foreseen that the total amount of data to be produced by the protoDUNE detectors will be of the order of a few petabytes (including commissioning runs with cosmic rays). Instantaneous and average data rates in the data transmission chain are expected to be substantial. For these reasons, capturing data streams generated by the protoDUNE DAQ systems, buffering of the data, performing fast QA type of analysis, transporting the data to sites external to CERN for processing (e.g. FNAL, BNL etc) requires resources and adequate planning.

\subsection{Prioritization}

All of the many elements in the chain of data acquisition, storage, distribution and processing are critically important in the sense that they are all required for the final results to be derived from the data. At the same time, protoDUNE has a critical dependency on the test beam availability (which is limited) provided by CERN and its schedule, which results in certains components of the data chain being more important than others in order to perform the measurements during a potentially limited time period. The priority components are the DAQ and the Raw Data Management System, which includes capturing the data coming out of the DAQ, transporting the data to persistent mass storage and prompt Quality Assurance which is required to ensure corrective action can be taken if the detector or certain system problems are identified in the QA process. The latter can be thought of as sophisticated monitoring done in near-time, which implies a ``few minute'' scale of processing.



\subsection{A note on the DAQ interface to the data handling system}

It is planned to have adequate buffering capability in the DAQ for both NP02 and NP04. In this case, “adequate” indicates in part conforming to a CERN requirement that the experiment must be able to keep taking data for a least 3 days at nominal rate, even if there is an occasional problem with the data link between the experiment site and CERN storage facilities, an issue with central storage or any type of similar outage. There is a difference in approach however in that
\begin{itemize}
\item Buffer depth in NP02 is larger, in order to make possible some processing right in the data room of the experiment. A number of middleware options are being explored for storage solution, in particular the BeeGFS file system.
\item In NP04 the emphasis is made on a more lightweight and fault tolerant which satisfies the general throughput requirement. No extensive processing is foreseen on the experiment site. Among the technical options for the buffer farm is xrootd.
\end{itemize}

\noindent
It is this “outer layer” of the data acquisition system in either experiment that will need to be interfaced with protoDUNE raw data management complex.

